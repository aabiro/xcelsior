# Xcelsior

> **A distributed GPU scheduler for Canadians who refuse to wait.**

Xcelsior is a lightweight, production-ready distributed GPU scheduling system that enables you to efficiently manage and orchestrate compute jobs across multiple GPU hosts. Built with simplicity and reliability in mind, it requires no heavyweight orchestration frameworksâ€”just Python, Docker, and determination.

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)

---

## Table of Contents

- [Features](#features)
- [Architecture](#architecture)
- [Prerequisites](#prerequisites)
- [Quick Start](#quick-start)
- [Installation](#installation)
  - [Automated Setup](#automated-setup)
  - [Manual Setup](#manual-setup)
- [Configuration](#configuration)
- [Usage](#usage)
  - [CLI Commands](#cli-commands)
  - [API Endpoints](#api-endpoints)
- [Deployment](#deployment)
  - [Single Machine Setup](#single-machine-setup)
  - [Multi-Machine Setup](#multi-machine-setup)
  - [Production Deployment](#production-deployment)
- [Worker Agent](#worker-agent)
- [Testing](#testing)
- [Troubleshooting](#troubleshooting)
- [FAQ](#faq)
- [Contributing](#contributing)
- [What's Next](#whats-next)
- [License](#license)
- [Acknowledgments](#acknowledgments)

---

## Features

### Core Scheduling (Phase 1-12)
- **Intelligent GPU Allocation**: Automatically schedules jobs to available GPUs based on VRAM requirements
- **Priority Queuing**: Multi-tier priority system (free, pro, enterprise) with configurable priorities
- **Health Monitoring**: Automated health checks with failover and job reassignment
- **Billing & Revenue Tracking**: Per-job billing with cost tracking and revenue analytics
- **Real-time Dashboard**: Web-based monitoring dashboard for jobs, hosts, and system metrics

### Security (Phase 13)
- **SSH Key Management**: Automated SSH key generation and distribution
- **API Token Authentication**: Bearer token authentication for all API endpoints
- **Secure Communication**: HTTPS support with TLS encryption

### Alerts & Notifications (Phase 14-15)
- **Email Alerts**: SMTP-based email notifications for job completion and failures
- **Telegram Integration**: Real-time alerts via Telegram bot
- **Configurable Alert Rules**: Customize alert conditions and recipients

### Advanced Features (Phase 16-20)
- **Docker Image Building**: Automated Docker image building and registry pushing
- **GPU Marketplace**: List and rent out idle GPU capacity to other users
- **Canada-Only Mode**: Optional geographic filtering for Canadian hosts
- **Auto-scaling**: Dynamic GPU provisioning with cloud provider integration
- **Multi-region Support**: Coordinate jobs across multiple data centers

---

## Architecture

Xcelsior consists of three main components:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         XCELSIOR SYSTEM                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚   Scheduler  â”‚â—„â”€â”€â”€â”€â”€â”€â–ºâ”‚  API Server  â”‚â—„â”€â”€â”€â”€â–ºâ”‚ Dashboard  â”‚ â”‚
â”‚  â”‚  (Core Logic)â”‚        â”‚  (FastAPI)   â”‚      â”‚  (Web UI)  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                                                       â”‚
â”‚         â”‚ Assigns Jobs                                         â”‚
â”‚         â–¼                                                       â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚              GPU Hosts (with Docker)                      â”‚ â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”              â”‚ â”‚
â”‚  â”‚  â”‚  Host 1  â”‚  â”‚  Host 2  â”‚  â”‚  Host N  â”‚              â”‚ â”‚
â”‚  â”‚  â”‚  RTX 2060â”‚  â”‚  RTX 3090â”‚  â”‚ RTX 4090 â”‚              â”‚ â”‚
â”‚  â”‚  â”‚  + Agent â”‚  â”‚  + Agent â”‚  â”‚  + Agent â”‚              â”‚ â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜              â”‚ â”‚
â”‚  â”‚        â”‚             â”‚             â”‚                     â”‚ â”‚
â”‚  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                     â”‚ â”‚
â”‚  â”‚                Report Status                              â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Components

1. **Scheduler (`scheduler.py`)**
   - Core scheduling logic and job queue management
   - GPU allocation algorithm based on VRAM requirements
   - Health monitoring and failover logic
   - Billing and revenue tracking
   - Persistence layer with file-based JSON storage

2. **API Server (`api.py`)**
   - RESTful API built with FastAPI
   - Authentication middleware for secure access
   - Web dashboard for monitoring
   - Marketplace endpoints for GPU rental

3. **CLI (`cli.py`)**
   - Command-line interface for all operations
   - Job submission and management
   - Host registration and monitoring
   - Billing and marketplace operations

4. **Worker Agent (`worker_agent.py`)**
   - Runs on each GPU host
   - Reports GPU status (VRAM usage) to scheduler
   - Lightweight Python daemon
   - Configurable reporting intervals

---

## Prerequisites

### System Requirements

**Scheduler Node:**
- Linux (Ubuntu 20.04+ or similar)
- Python 3.11 or higher
- 1 GB RAM minimum
- 10 GB disk space

**GPU Worker Nodes:**
- Linux (Ubuntu 20.04+ or similar)
- Python 3.11 or higher
- NVIDIA GPU with CUDA support
- NVIDIA drivers (version 525+ recommended)
- Docker 24.0+ with NVIDIA Container Toolkit
- Network connectivity to scheduler node

### Software Dependencies

**Required:**
- Python 3.11+
- pip (Python package manager)
- Docker (for GPU workers)
- NVIDIA Container Toolkit (for GPU workers)

**Optional:**
- systemd (for service management)
- nginx/Apache (for reverse proxy)
- Let's Encrypt (for SSL certificates)

---

## Quick Start

### Single RTX 2060 Setup

If you have a single machine with an RTX 2060 and want to start immediately:

```bash
# 1. Clone the repository
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior

# 2. Run automated setup
chmod +x setup.sh
./setup.sh

# 3. Follow the prompts - choose "Single machine (scheduler + worker)"

# 4. Submit your first job
source venv/bin/activate
python cli.py run bert-base-uncased 4.0

# 5. Check job status
python cli.py jobs

# 6. Start the API server (optional)
uvicorn api:app --host 0.0.0.0 --port 8000

# 7. Visit the dashboard
# Open http://localhost:8000/dashboard in your browser
```

That's it! You're now running Xcelsior on your RTX 2060.

---

## Installation

### Automated Setup

The easiest way to install Xcelsior is using the automated setup script:

```bash
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior
chmod +x setup.sh
./setup.sh
```

The setup script will:
1. Detect your OS and Python version
2. Check for Docker and NVIDIA drivers
3. Optionally install missing dependencies
4. Create a Python virtual environment
5. Install all Python packages
6. Configure environment variables
7. Register your GPU host (if applicable)
8. Run verification tests
9. Provide next steps

**Setup Modes:**

1. **Single machine (scheduler + worker)**: Everything runs on one machine with GPU(s)
2. **Scheduler only**: Sets up just the scheduler/API server (no GPU required)
3. **Worker only**: Sets up a GPU worker that connects to existing scheduler

### Manual Setup

If you prefer to set up manually:

#### 1. Clone the Repository

```bash
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior
```

#### 2. Create Virtual Environment

```bash
python3.11 -m venv venv
source venv/bin/activate  # On Linux/Mac
# OR
venv\Scripts\activate  # On Windows
```

#### 3. Install Dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

#### 4. Configure Environment

```bash
cp .env.example .env
# Edit .env with your settings
nano .env
```

**Required settings:**
- `XCELSIOR_API_TOKEN`: Generate with `python -c "import secrets; print(secrets.token_urlsafe(32))"`

**Optional settings:**
- Email/Telegram alerts
- Docker registry
- Marketplace configuration
- Auto-scaling settings

#### 5. Install Docker & NVIDIA Container Toolkit (GPU hosts only)

**Ubuntu/Debian:**
```bash
# Install Docker
curl -fsSL https://get.docker.com -o get-docker.sh
sudo sh get-docker.sh
sudo usermod -aG docker $USER

# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/nvidia-docker/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

#### 6. Register GPU Hosts

On each GPU host:

```bash
# Get GPU info
nvidia-smi --query-gpu=name,memory.total --format=csv,noheader

# Register with scheduler
python cli.py host-add \
  --id my-rtx-2060 \
  --ip 192.168.1.100 \
  --gpu "RTX 2060" \
  --vram 6.0 \
  --free-vram 6.0 \
  --rate 0.15
```

#### 7. Start Services

**Scheduler/API:**
```bash
# Development
uvicorn api:app --host 0.0.0.0 --port 8000

# Production (with gunicorn)
gunicorn api:app -w 4 -k uvicorn.workers.UvicornWorker --bind 0.0.0.0:8000
```

**Worker Agent:**
```bash
export XCELSIOR_HOST_ID=my-rtx-2060
export XCELSIOR_SCHEDULER_URL=http://scheduler-ip:8000
export XCELSIOR_API_TOKEN=your_token_here
python worker_agent.py
```

---

## Configuration

Xcelsior uses environment variables for configuration. Copy `.env.example` to `.env` and customize:

### Core Settings

```bash
# API Security
XCELSIOR_API_TOKEN=your_secure_token_here
XCELSIOR_SSH_KEY_PATH=~/.ssh/xcelsior
XCELSIOR_SSH_USER=xcelsior
```

### Email Alerts

```bash
XCELSIOR_SMTP_HOST=smtp.gmail.com
XCELSIOR_SMTP_PORT=587
XCELSIOR_SMTP_USER=your_email@gmail.com
XCELSIOR_SMTP_PASS=your_app_password
XCELSIOR_EMAIL_FROM=xcelsior@yourdomain.com
XCELSIOR_EMAIL_TO=admin@yourdomain.com
```

### Telegram Alerts

```bash
XCELSIOR_TG_TOKEN=your_telegram_bot_token
XCELSIOR_TG_CHAT_ID=your_chat_id
```

### Marketplace

```bash
XCELSIOR_PLATFORM_CUT=0.20  # 20% platform fee
```

### Auto-scaling

```bash
XCELSIOR_AUTOSCALE=false
XCELSIOR_AUTOSCALE_MAX=20
XCELSIOR_AUTOSCALE_PROVIDER=aws  # or gcp, azure
```

### Geographic Filtering

```bash
XCELSIOR_CANADA_ONLY=false  # Set to true to only use Canadian hosts
```

---

## Usage

### CLI Commands

Xcelsior provides a comprehensive CLI for all operations:

#### Job Management

**Submit a job:**
```bash
python cli.py run MODEL_NAME VRAM_GB [OPTIONS]

# Examples:
python cli.py run bert-base-uncased 4.0
python cli.py run llama-13b 24.0 --priority 10
python cli.py run stable-diffusion 8.0 --tier pro
```

**List jobs:**
```bash
python cli.py jobs [--status STATUS]

# Examples:
python cli.py jobs                    # All jobs
python cli.py jobs --status queued    # Only queued
python cli.py jobs --status running   # Only running
python cli.py jobs --status completed # Only completed
```

**Get job details:**
```bash
python cli.py job JOB_ID

# Example:
python cli.py job abc123-def456
```

**Cancel a job:**
```bash
python cli.py cancel JOB_ID
```

**Process queue manually:**
```bash
python cli.py process
```

#### Host Management

**Register a host:**
```bash
python cli.py host-add \
  --id HOST_ID \
  --ip IP_ADDRESS \
  --gpu GPU_MODEL \
  --vram TOTAL_VRAM_GB \
  --free-vram FREE_VRAM_GB \
  --rate COST_PER_HOUR

# Example:
python cli.py host-add \
  --id gaming-rig-01 \
  --ip 192.168.1.100 \
  --gpu "RTX 3090" \
  --vram 24.0 \
  --free-vram 24.0 \
  --rate 0.50
```

**Remove a host:**
```bash
python cli.py host-rm HOST_ID
```

**List hosts:**
```bash
python cli.py hosts [--all]

# Examples:
python cli.py hosts       # Active hosts only
python cli.py hosts --all # All hosts including inactive
```

**Check host health:**
```bash
python cli.py check
```

#### Priority Tiers

**List available tiers:**
```bash
python cli.py tiers
```

#### SSH Key Management

**Generate SSH keypair:**
```bash
python cli.py ssh-keygen
```

**Get public key:**
```bash
python cli.py ssh-pubkey
```

#### Billing

**Bill a completed job:**
```bash
python cli.py bill JOB_ID
```

**Bill all completed jobs:**
```bash
python cli.py bill-all
```

**Get total revenue:**
```bash
python cli.py revenue
```

**View billing records:**
```bash
python cli.py billing
```

#### Docker Integration

**Build and push Docker image:**
```bash
python cli.py build-push \
  --job JOB_ID \
  --image IMAGE_NAME \
  --registry REGISTRY_URL

# Example:
python cli.py build-push \
  --job abc123-def456 \
  --image myapp:v1.0 \
  --registry registry.example.com
```

**List builds:**
```bash
python cli.py builds
```

**Generate Dockerfile:**
```bash
python cli.py dockerfile \
  --base BASE_IMAGE \
  --deps DEPENDENCIES

# Example:
python cli.py dockerfile \
  --base python:3.11-slim \
  --deps "torch transformers"
```

#### Marketplace

**List your rig on marketplace:**
```bash
python cli.py list-rig \
  --host HOST_ID \
  --rate HOURLY_RATE \
  --description "RTX 3090 for ML training"
```

**Unlist your rig:**
```bash
python cli.py unlist-rig --host HOST_ID
```

**Browse marketplace:**
```bash
python cli.py marketplace
```

**View marketplace stats:**
```bash
python cli.py marketplace-stats
```

#### Health Monitoring

**Start health monitor daemon:**
```bash
python cli.py health-start [--interval SECONDS]

# Example:
python cli.py health-start --interval 30
```

#### Failover

**Trigger failover for a host:**
```bash
python cli.py failover --host HOST_ID
```

**Requeue a failed job:**
```bash
python cli.py requeue --job JOB_ID
```

#### Auto-scaling

**Add host to auto-scale pool:**
```bash
python cli.py pool-add \
  --provider aws \
  --instance-type g4dn.xlarge \
  --region us-east-1
```

**Remove host from pool:**
```bash
python cli.py pool-rm --pool-id POOL_ID
```

**List auto-scale pool:**
```bash
python cli.py pool-list
```

**Manually trigger auto-scale:**
```bash
python cli.py autoscale
```

#### Configuration

**Configure alerts:**
```bash
python cli.py alerts \
  --email admin@example.com \
  --telegram CHAT_ID
```

**Set Canada-only mode:**
```bash
python cli.py canada-only --enable
```

---

### API Endpoints

Xcelsior provides a RESTful API for programmatic access.

**Base URL:** `http://your-server:8000`

**Authentication:** Include API token in header:
```
Authorization: Bearer YOUR_TOKEN
```

Or as query parameter:
```
?token=YOUR_TOKEN
```

#### Host Endpoints

**Register/Update Host**
```http
PUT /host
Content-Type: application/json

{
  "host_id": "rig-01",
  "ip": "192.168.1.100",
  "gpu_model": "RTX 3090",
  "total_vram_gb": 24.0,
  "free_vram_gb": 24.0,
  "cost_per_hour": 0.50
}
```

**Remove Host**
```http
DELETE /host/{host_id}
```

**List Hosts**
```http
GET /hosts?active_only=true
```

**Check Host Health**
```http
POST /hosts/check
```

#### Job Endpoints

**Submit Job**
```http
POST /job
Content-Type: application/json

{
  "name": "bert-training",
  "vram_needed_gb": 8.0,
  "priority": 5,
  "tier": "pro"
}
```

**List Jobs**
```http
GET /jobs?status=running
```

**Get Job Details**
```http
GET /job/{job_id}
```

**Update Job Status**
```http
PATCH /job/{job_id}/status
Content-Type: application/json

{
  "status": "completed",
  "host_id": "rig-01"
}
```

**Process Queue**
```http
POST /queue/process
```

#### Billing Endpoints

**Bill Job**
```http
POST /job/{job_id}/bill
```

**Bill All Completed**
```http
POST /billing/bill-all
```

**Get Total Revenue**
```http
GET /billing/revenue
```

**List Billing Records**
```http
GET /billing
```

#### SSH Endpoints

**Generate SSH Keypair**
```http
POST /ssh/generate
```

**Get Public Key**
```http
GET /ssh/pubkey
```

#### Marketplace Endpoints

**List Rig**
```http
POST /marketplace/list
Content-Type: application/json

{
  "host_id": "rig-01",
  "hourly_rate": 0.75,
  "description": "RTX 3090 24GB"
}
```

**Unlist Rig**
```http
DELETE /marketplace/unlist/{host_id}
```

**Get Marketplace Listings**
```http
GET /marketplace
```

**Marketplace Stats**
```http
GET /marketplace/stats
```

#### Dashboard

**Web Dashboard**
```http
GET /dashboard
```

Opens the web-based monitoring dashboard showing:
- Active jobs
- Available hosts
- Queue status
- Revenue metrics
- System health

#### API Documentation

**Interactive API Docs (Swagger UI)**
```http
GET /docs
```

**OpenAPI Schema**
```http
GET /openapi.json
```

---

## Deployment

### Single Machine Setup

Perfect for development or small-scale production with 1-4 GPUs:

```bash
# 1. Install Xcelsior
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior
./setup.sh
# Choose: "1. Single machine (scheduler + worker)"

# 2. Start API server
source venv/bin/activate
uvicorn api:app --host 0.0.0.0 --port 8000 &

# 3. Start worker agent
export XCELSIOR_HOST_ID=local-gpu
export XCELSIOR_SCHEDULER_URL=http://localhost:8000
python worker_agent.py &

# 4. Submit jobs
python cli.py run my-model 8.0
```

### Multi-Machine Setup

For larger deployments with dedicated scheduler and multiple GPU workers:

#### Scheduler Node

```bash
# 1. Install on scheduler machine (no GPU required)
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior
./setup.sh
# Choose: "2. Scheduler only"

# 2. Configure .env
cp .env.example .env
nano .env
# Set XCELSIOR_API_TOKEN

# 3. Start API server
source venv/bin/activate
gunicorn api:app \
  -w 4 \
  -k uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000 \
  --access-logfile - \
  --error-logfile -
```

#### Worker Nodes (Repeat for each GPU host)

```bash
# 1. Install on GPU machine
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior
./setup.sh
# Choose: "3. Worker only"

# 2. Configure worker
export XCELSIOR_HOST_ID=gpu-worker-01
export XCELSIOR_SCHEDULER_URL=http://scheduler-ip:8000
export XCELSIOR_API_TOKEN=your_token
export XCELSIOR_COST_PER_HOUR=0.50

# 3. Start worker agent
source venv/bin/activate
python worker_agent.py
```

### Production Deployment

For production environments, use systemd services for automatic startup and recovery:

#### 1. Create Xcelsior User

```bash
sudo useradd -r -s /bin/bash -d /opt/xcelsior xcelsior
sudo mkdir -p /opt/xcelsior
sudo chown xcelsior:xcelsior /opt/xcelsior
```

#### 2. Install Xcelsior

```bash
sudo -u xcelsior bash
cd /opt/xcelsior
git clone https://github.com/aabiro/xcelsior.git .
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
cp .env.example .env
nano .env  # Configure settings
```

#### 3. Install Systemd Services

**API Service:**
```bash
sudo cp xcelsior-api.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable xcelsior-api
sudo systemctl start xcelsior-api
```

**Worker Service (on GPU hosts):**
```bash
sudo cp xcelsior-worker.service /etc/systemd/system/
# Edit service file with correct environment variables
sudo nano /etc/systemd/system/xcelsior-worker.service
sudo systemctl daemon-reload
sudo systemctl enable xcelsior-worker
sudo systemctl start xcelsior-worker
```

**Health Monitor Service:**
```bash
sudo cp xcelsior-health.service /etc/systemd/system/
sudo systemctl daemon-reload
sudo systemctl enable xcelsior-health
sudo systemctl start xcelsior-health
```

#### 4. Check Service Status

```bash
sudo systemctl status xcelsior-api
sudo systemctl status xcelsior-worker
sudo systemctl status xcelsior-health

# View logs
sudo journalctl -u xcelsior-api -f
sudo journalctl -u xcelsior-worker -f
```

#### 5. Configure Reverse Proxy (Optional)

**Nginx configuration:**
```nginx
server {
    listen 80;
    server_name xcelsior.example.com;

    location / {
        proxy_pass http://localhost:8000;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}
```

#### 6. SSL/TLS with Let's Encrypt

```bash
sudo apt-get install certbot python3-certbot-nginx
sudo certbot --nginx -d xcelsior.example.com
```

#### 7. Firewall Configuration

```bash
# On scheduler
sudo ufw allow 8000/tcp
sudo ufw allow 22/tcp
sudo ufw enable

# On workers
sudo ufw allow from SCHEDULER_IP to any port 22
sudo ufw enable
```

---

## Worker Agent

The worker agent is a lightweight Python daemon that runs on each GPU host and reports status to the scheduler.

### How It Works

1. **Monitors GPU Status**: Queries `nvidia-smi` every 5 seconds (configurable)
2. **Reports to Scheduler**: Sends updated VRAM usage via API
3. **Handles Failures**: Retry logic with exponential backoff
4. **Runs as Daemon**: Can be managed via systemd

### Configuration

Set these environment variables before running:

```bash
# Required
export XCELSIOR_HOST_ID=your-unique-host-id
export XCELSIOR_SCHEDULER_URL=http://scheduler-ip:8000
export XCELSIOR_API_TOKEN=your_api_token

# Optional
export XCELSIOR_COST_PER_HOUR=0.50
export XCELSIOR_REPORT_INTERVAL=5
```

### Running the Agent

**Foreground (for testing):**
```bash
python worker_agent.py
```

**Background:**
```bash
nohup python worker_agent.py > worker.log 2>&1 &
```

**With systemd:**
```bash
sudo systemctl start xcelsior-worker
sudo systemctl status xcelsior-worker
```

### Troubleshooting Worker Agent

**Check if agent is running:**
```bash
ps aux | grep worker_agent
```

**View agent logs:**
```bash
# If running with systemd
sudo journalctl -u xcelsior-worker -f

# If running in background
tail -f worker.log
```

**Test nvidia-smi access:**
```bash
nvidia-smi --query-gpu=memory.free --format=csv,noheader,nounits
```

**Test scheduler connectivity:**
```bash
curl -H "Authorization: Bearer $XCELSIOR_API_TOKEN" \
  $XCELSIOR_SCHEDULER_URL/hosts
```

---

## Testing

Xcelsior includes comprehensive test suites for scheduler and API functionality.

### Running Tests

**All tests:**
```bash
python -m pytest test_scheduler.py test_api.py -v
```

**Specific test file:**
```bash
python -m pytest test_scheduler.py -v
python -m pytest test_api.py -v
```

**With coverage:**
```bash
python -m pytest test_scheduler.py test_api.py -v --cov=. --cov-report=html
```

**Specific test class:**
```bash
python -m pytest test_scheduler.py::TestAllocate -v
```

**Specific test method:**
```bash
python -m pytest test_scheduler.py::TestAllocate::test_no_hosts_returns_none -v
```

### Test Structure

Tests use `pytest` with temporary directories for data isolation:

- `test_scheduler.py`: Core scheduling logic tests (200+ tests)
- `test_api.py`: API endpoint tests

Each test automatically:
- Creates temporary data files
- Cleans up after execution
- Isolates state between tests

### Writing New Tests

Follow the existing patterns:

```python
def test_my_feature(self):
    """Test description."""
    # Setup
    register_host("test-host", "1.2.3.4", "RTX 3090", 24.0, 24.0, 0.5)
    
    # Execute
    job = submit_job("my-model", 8.0)
    
    # Assert
    assert job["status"] == "queued"
    assert job["vram_needed_gb"] == 8.0
```

---

## Troubleshooting

### Common Issues

#### Issue: "nvidia-smi: command not found"

**Cause:** NVIDIA drivers not installed or not in PATH

**Solution:**
```bash
# Check if drivers are installed
lspci | grep -i nvidia

# Install drivers (Ubuntu/Debian)
sudo apt-get update
sudo apt-get install nvidia-driver-525

# Reboot
sudo reboot
```

#### Issue: "docker: Error response from daemon: could not select device driver"

**Cause:** NVIDIA Container Toolkit not installed

**Solution:**
```bash
# Install NVIDIA Container Toolkit
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/nvidia-docker/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/nvidia-docker/$distribution/nvidia-docker.list | \
  sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
  sudo tee /etc/apt/sources.list.d/nvidia-docker.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# Test
docker run --rm --gpus all nvidia/cuda:11.8.0-base-ubuntu22.04 nvidia-smi
```

#### Issue: "401 Unauthorized" from API

**Cause:** Missing or incorrect API token

**Solution:**
```bash
# Generate new token
python -c "import secrets; print(secrets.token_urlsafe(32))"

# Set in .env file
echo "XCELSIOR_API_TOKEN=your_new_token" >> .env

# Use in requests
curl -H "Authorization: Bearer your_new_token" http://localhost:8000/hosts
```

#### Issue: Worker agent not reporting status

**Cause:** Network connectivity or configuration issue

**Solution:**
```bash
# Test scheduler connectivity
curl http://scheduler-ip:8000/

# Check worker environment variables
env | grep XCELSIOR

# Check worker logs
sudo journalctl -u xcelsior-worker -n 50

# Restart worker
sudo systemctl restart xcelsior-worker
```

#### Issue: Jobs stuck in "queued" state

**Cause:** No hosts available or queue not being processed

**Solution:**
```bash
# Check host status
python cli.py hosts

# Manually process queue
python cli.py process

# Check host health
python cli.py check

# Restart health monitor
sudo systemctl restart xcelsior-health
```

#### Issue: Permission denied errors

**Cause:** File permissions or user permissions

**Solution:**
```bash
# Fix file permissions
sudo chown -R xcelsior:xcelsior /opt/xcelsior
sudo chmod 755 /opt/xcelsior

# Add user to docker group (for workers)
sudo usermod -aG docker xcelsior
# Logout and login again
```

#### Issue: High memory usage

**Cause:** Large number of jobs or hosts in JSON files

**Solution:**
```bash
# Archive old completed jobs
python cli.py jobs --status completed > completed_jobs.json
# Manually clean up jobs.json (keep only active jobs)

# Consider implementing log rotation
sudo logrotate /etc/logrotate.d/xcelsior
```

### Debug Mode

Enable debug logging for detailed troubleshooting:

```python
# In scheduler.py or api.py
log = setup_logging(level=logging.DEBUG)
```

Or via CLI:
```bash
export XCELSIOR_DEBUG=1
python cli.py run my-model 8.0
```

### Getting Help

1. Check this README thoroughly
2. Review logs: `cat xcelsior.log`
3. Check test output: `python -m pytest -v`
4. Open an issue: https://github.com/aabiro/xcelsior/issues

---

## FAQ

### General

**Q: What does "Xcelsior" mean?**
A: Xcelsior is Latin for "ever upward" â€” the spirit of continuous improvement and refusing to settle for mediocrity.

**Q: Why was Xcelsior created?**
A: To provide a simple, lightweight GPU scheduling system without the complexity of Kubernetes or other heavyweight orchestration frameworks.

**Q: Is Xcelsior production-ready?**
A: Yes! It's been designed with production use in mind, including health monitoring, failover, billing, and security features.

**Q: Can I use Xcelsior for commercial purposes?**
A: Yes, Xcelsior is MIT licensed. Use it for whatever you want.

### Technical

**Q: What GPUs are supported?**
A: Any NVIDIA GPU with CUDA support. We've tested with RTX 2060, 3090, 4090, A100, and H100.

**Q: Can I mix different GPU models?**
A: Yes! The scheduler intelligently allocates jobs based on VRAM requirements.

**Q: How does scheduling work?**
A: Jobs are assigned to hosts with sufficient free VRAM. Priority and tier affect queue ordering.

**Q: What happens if a host fails?**
A: The health monitor detects failures and automatically reassigns running jobs to other hosts.

**Q: Can I run multiple schedulers?**
A: Not currently. Run a single scheduler and connect all workers to it.

**Q: Does it support multi-GPU jobs?**
A: Not yet, but multi-GPU support is on the roadmap (see What's Next).

**Q: How is billing calculated?**
A: Per-job billing based on runtime and host cost per hour: `cost = runtime_hours * host_cost_per_hour`

### Operations

**Q: How do I update Xcelsior?**
A: Pull latest changes and restart services:
```bash
git pull origin main
pip install -r requirements.txt
sudo systemctl restart xcelsior-api xcelsior-worker
```

**Q: How do I backup Xcelsior data?**
A: Backup these JSON files:
```bash
tar -czf xcelsior-backup.tar.gz hosts.json jobs.json billing.json marketplace.json
```

**Q: Can I run Xcelsior in Docker?**
A: Yes, but the workers need access to nvidia-smi. Use `--gpus all` and mount the driver.

**Q: What's the recommended server size?**
A: Scheduler: 1 CPU, 1GB RAM. Workers: Depends on your workload.

**Q: How many jobs can Xcelsior handle?**
A: Tested with 10,000+ jobs. Performance depends on hardware and job complexity.

### Marketplace

**Q: How does the marketplace work?**
A: List idle GPUs for rent. Others submit jobs that run on your hardware. You earn revenue minus platform cut.

**Q: What's the platform cut?**
A: Configurable via `XCELSIOR_PLATFORM_CUT` (default: 20%)

**Q: How do I get paid?**
A: Billing records are tracked in `billing.json`. Payment integration is up to you.

---

## Contributing

We welcome contributions! Here's how to get involved:

### Reporting Issues

Found a bug? Have a feature request?

1. Check existing issues: https://github.com/aabiro/xcelsior/issues
2. Create a new issue with:
   - Clear description
   - Steps to reproduce (for bugs)
   - Expected vs actual behavior
   - Your environment (OS, Python version, GPU model)

### Submitting Pull Requests

1. Fork the repository
2. Create a feature branch: `git checkout -b feature/my-feature`
3. Make your changes
4. Add tests for new functionality
5. Run test suite: `python -m pytest -v`
6. Commit with clear messages: `git commit -m "Add feature X"`
7. Push to your fork: `git push origin feature/my-feature`
8. Open a pull request

### Code Style

Follow the existing code style:
- Comments: Clear, concise, with ASCII art separators
- Functions: Docstrings for all public functions
- Naming: Descriptive variable names
- Error handling: Explicit exception handling
- Logging: Log important events and errors

Example:
```python
def my_function(param):
    """
    Brief description of what the function does.
    Clear. Concise. No fluff.
    """
    try:
        # Implementation
        result = do_something(param)
        log.info(f"Operation completed: {result}")
        return result
    except Exception as e:
        log.error(f"Operation failed: {e}")
        raise
```

### Development Setup

```bash
git clone https://github.com/aabiro/xcelsior.git
cd xcelsior
python3.11 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
pip install pytest-cov
```

### Running Tests

```bash
# All tests
python -m pytest -v

# With coverage
python -m pytest --cov=. --cov-report=html

# Specific tests
python -m pytest test_scheduler.py -v
```

### Documentation

When adding features:
- Update this README
- Add docstrings to new functions
- Update API documentation if needed
- Add examples to help users

---

## What's Next

Xcelsior is continuously evolving. Here's what's on the roadmap:

### Short Term (Next Release)

- [ ] **Multi-GPU jobs**: Support for jobs requiring multiple GPUs
- [ ] **Web UI improvements**: Enhanced dashboard with real-time updates
- [ ] **Docker image caching**: Speed up job startup with local image cache
- [ ] **Job dependencies**: Support for DAG-based job workflows
- [ ] **Cost estimation**: Predict job costs before submission

### Medium Term (3-6 months)

- [ ] **Container orchestration**: Better Docker lifecycle management
- [ ] **Storage integration**: S3/GCS support for job artifacts
- [ ] **Authentication**: User accounts and role-based access control
- [ ] **Metrics & monitoring**: Prometheus/Grafana integration
- [ ] **Job templates**: Reusable job configurations

### Long Term (6-12 months)

- [ ] **Kubernetes integration**: Option to deploy on K8s clusters
- [ ] **GPU pooling**: Share GPU memory across multiple small jobs
- [ ] **Auto-tuning**: ML-based resource optimization
- [ ] **Federation**: Connect multiple Xcelsior clusters
- [ ] **Marketplace v2**: Public marketplace with ratings and reviews

### Experimental

- [ ] **WASM support**: Run lightweight inference in WebAssembly
- [ ] **Edge deployment**: Support for edge GPU devices
- [ ] **Quantum computing**: Integration with quantum simulators (just kidding... or are we?)

Want to contribute to any of these? Open an issue to discuss!

---

## License

Xcelsior is released under the [MIT License](LICENSE).

```
MIT License

Copyright (c) 2024 Xcelsior Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

---

## Acknowledgments

Xcelsior was built with:
- **FastAPI**: Modern, fast web framework for Python
- **Uvicorn**: Lightning-fast ASGI server
- **pytest**: Comprehensive testing framework
- **Docker**: Container platform for consistent environments
- **NVIDIA**: GPU hardware and CUDA toolkit

Special thanks to:
- The open-source community for inspiration and tools
- Early adopters who provided valuable feedback
- Contributors who helped improve Xcelsior

---

## Support

Need help? Here's how to get support:

### Documentation
- This README (you're reading it!)
- Inline code comments
- API docs: http://your-server:8000/docs

### Community
- GitHub Issues: https://github.com/aabiro/xcelsior/issues
- Discussions: https://github.com/aabiro/xcelsior/discussions

### Commercial Support
For enterprise support, training, or consulting:
- Email: support@xcelsior.example.com
- Custom deployment assistance
- SLA-backed support contracts
- On-site training

---

## Statistics

- **Lines of Code**: ~2,000
- **Test Coverage**: 90%+
- **Supported Python Versions**: 3.11+
- **Supported Linux Distributions**: Ubuntu 20.04+, Debian 11+, CentOS 8+
- **Supported GPUs**: Any NVIDIA GPU with CUDA support
- **Maximum Hosts**: Tested with 100+ GPU hosts
- **Maximum Jobs**: Tested with 10,000+ concurrent jobs

---

## Release Notes

### v1.0.0 (Current)

**Features:**
- Complete 20-phase implementation
- Multi-tier priority system
- GPU marketplace
- Auto-scaling support
- Health monitoring and failover
- Comprehensive billing
- Email and Telegram alerts
- SSH key management
- Docker image building
- Canada-only mode

**Improvements:**
- File-locking for safe concurrent access
- Retry logic with exponential backoff
- Comprehensive test coverage
- Production-ready systemd services

**Known Issues:**
- Single-GPU jobs only (multi-GPU coming soon)
- Manual payment processing for marketplace
- Limited to file-based storage (database support coming)

---

**Built with determination in Canada. ðŸ‡¨ðŸ‡¦**

**Ever upward. Xcelsior.**
